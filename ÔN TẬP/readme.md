Ã”n Táº­p AI - Lab Cuá»‘i Ká»³
Há» tÃªn: Nguyá»…n Háº¡n VÅ©
MSSV: 2374802010571
MÃ´n há»c: Nháº­p mÃ´n TrÃ­ tuá»‡ nhÃ¢n táº¡o
Giáº£ng viÃªn: Nguyá»…n ThÃ¡i Anh

CÃ‚U 1: TÃŒM DFS TRÃŠN Äá»’ THá»Š
YÃªu cáº§u: Duyá»‡t Ä‘á»“ thá»‹ theo chiá»u sÃ¢u (DFS) tá»« má»™t Ä‘á»‰nh xuáº¥t phÃ¡t.

Äá»“ thá»‹:


HÆ°á»›ng dáº«n:

Biá»ƒu diá»…n Ä‘á»“ thá»‹ dÆ°á»›i dáº¡ng danh sÃ¡ch ká».

Viáº¿t hÃ m DFS Ä‘á»‡ quy Ä‘á»ƒ in thá»© tá»± cÃ¡c Ä‘á»‰nh Ä‘Æ°á»£c thÄƒm.

Bá» qua trá»ng sá»‘ cáº¡nh vÃ¬ DFS khÃ´ng phá»¥ thuá»™c vÃ o trá»ng sá»‘.

VÃ­ dá»¥ Python:

python
Sao chÃ©p
Chá»‰nh sá»­a
graph = {
    1: [2, 4],
    2: [1, 3, 5],
    3: [2, 5, 7, 9],
    4: [1, 5, 6],
    5: [2, 3, 4, 6],
    6: [4, 5, 7],
    7: [3, 6, 8, 9],
    8: [7, 9],
    9: [3, 7, 8]
}

visited = set()

def dfs(node):
    if node not in visited:
        print(node, end=" ")
        visited.add(node)
        for neighbor in graph[node]:
            dfs(neighbor)

dfs(1)  # Hoáº·c Ä‘á»•i Ä‘á»‰nh xuáº¥t phÃ¡t tÃ¹y Ä‘á» bÃ i
CÃ‚U 2: Tá»‘i Æ¯u HÃ³a HÃ m Má»™t Biáº¿n
BÃ i toÃ¡n:
TÃ¬m giÃ¡ trá»‹ lá»›n nháº¥t cá»§a hÃ m:

ğ‘“
(
ğ‘¥
)
=
âˆ’
ğ‘¥
2
+
10
ğ‘¥
+
50
,
ğ‘¥
âˆˆ
[
0
,
10
]
f(x)=âˆ’x 
2
 +10x+50,xâˆˆ[0,10]
Ã tÆ°á»Ÿng:

Ãp dá»¥ng thuáº­t toÃ¡n di truyá»n (Genetic Algorithm - GA)

MÃ£ hÃ³a x dÆ°á»›i dáº¡ng chuá»—i nhá»‹ phÃ¢n

Fitness lÃ  giÃ¡ trá»‹ cá»§a hÃ m f(x)

Thá»±c hiá»‡n chá»n lá»c, lai ghÃ©p vÃ  Ä‘á»™t biáº¿n qua nhiá»u tháº¿ há»‡

Káº¿t quáº£ mong Ä‘á»£i:
x gáº§n 5, vÃ¬ táº¡i Ä‘Ã³ f(x) Ä‘áº¡t cá»±c Ä‘áº¡i.

CÃ‚U 3: PhÃ¢n Loáº¡i ChÃ³ vÃ  MÃ¨o báº±ng CNN
Dá»¯ liá»‡u:
Tá»« Kaggle: Dogs vs Cats Dataset

YÃªu cáº§u:

XÃ¢y dá»±ng mÃ´ hÃ¬nh há»c sÃ¢u CNN Ä‘á»ƒ phÃ¢n loáº¡i hÃ¬nh áº£nh chÃ³/mÃ¨o

CÃ¡c bÆ°á»›c:

Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (resize, augment)

XÃ¢y dá»±ng mÃ´ hÃ¬nh CNN (Keras/TensorFlow)

Huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh

Kiá»ƒm thá»­ trÃªn áº£nh má»›i

Gá»£i Ã½ cáº¥u trÃºc CNN Ä‘Æ¡n giáº£n:

python
Sao chÃ©p
Chá»‰nh sá»­a
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')
])
CÃ‚U 4: Dá»± ÄoÃ¡n ChÆ¡i hay KhÃ´ng báº±ng Naive Bayes
Táº­p dá»¯ liá»‡u:

Day	Outlook	Temperature	Humidity	Wind	Play
...	...	...	...	...	...

YÃªu cáº§u:

Dá»± Ä‘oÃ¡n cá»™t Play (Yes/No) báº±ng mÃ´ hÃ¬nh Naive Bayes

Sá»­ dá»¥ng dá»¯ liá»‡u phÃ¢n loáº¡i (Categorical)

Ãp dá»¥ng Laplace smoothing (náº¿u cáº§n)

CÃ¡c bÆ°á»›c:

MÃ£ hÃ³a Ä‘áº·c trÆ°ng thÃ nh dáº¡ng sá»‘ (Label Encoding)

Ãp dá»¥ng Naive Bayes phÃ¢n loáº¡i rá»i ráº¡c (sklearn.naive_bayes.CategoricalNB)

Dá»± Ä‘oÃ¡n máº«u má»›i

VÃ­ dá»¥ Python (dÃ¹ng sklearn):

python
Sao chÃ©p
Chá»‰nh sá»­a
from sklearn.naive_bayes import CategoricalNB
from sklearn.preprocessing import LabelEncoder
import pandas as pd

# Giáº£ sá»­ báº¡n Ä‘Ã£ nháº­p DataFrame `df` tá»« báº£ng
for col in ['Outlook', 'Temperature', 'Humidity', 'Wind', 'Play']:
    df[col] = LabelEncoder().fit_transform(df[col])

X = df[['Outlook', 'Temperature', 'Humidity', 'Wind']]
y = df['Play']

model = CategoricalNB()
model.fit(X, y)

# Dá»± Ä‘oÃ¡n
sample = [[1, 2, 0, 1]]  # TÃ¹y máº«u má»›i
print("Dá»± Ä‘oÃ¡n:", model.predict(sample))
Káº¿t luáº­n
Trong 4 cÃ¢u há»i Ã´n táº­p, em Ä‘Ã£ Ã¡p dá»¥ng cÃ¡c ká»¹ thuáº­t cá»‘t lÃµi cá»§a trÃ­ tuá»‡ nhÃ¢n táº¡o:

Cáº¥u trÃºc dá»¯ liá»‡u & thuáº­t toÃ¡n (DFS)

Tá»‘i Æ°u hoÃ¡ vá»›i thuáº­t toÃ¡n di truyá»n

Há»c sÃ¢u vá»›i CNN

Há»c mÃ¡y vá»›i Naive Bayes
